{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cb0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/cdot/.local/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/cdot/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91eb618",
   "metadata": {},
   "source": [
    "#### First we need to configure the any pyspark application with SparkConf() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e2a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4248c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local[2]\n",
      "Pyspark Cofiguration demo\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"Pyspark Cofiguration demo\").setMaster(\"local[2]\")\n",
    "#spark = SparkSession.builder.appName(\"FirstSparksession\").getOrCreate()\n",
    "print(conf.get(\"spark.master\"))\n",
    "print(conf.get(\"spark.app.name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53130347",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc9b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: findspark in ./.local/lib/python3.10/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c8ee2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa70224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89aa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession.builder.appName(\"First\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fdbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a19bb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {\"date\": [\"01-01-2015\",\"02-01-2015\",\"03-01-2015\",\"06-01-2015\",\n",
    "        \"07-01-2015\",\"11-01-2015\",\"12-01-2015\",\"13-01-2015\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8baabfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(di)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e176e8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(pd.to_datetime(df[\"date\"], dayfirst=True, format = \"%d-%m-%Y\"))\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71261619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2015-01-01    1\n",
       "2015-01-02    1\n",
       "2015-01-03    1\n",
       "2015-01-06    1\n",
       "2015-01-07    1\n",
       "2015-01-11    1\n",
       "2015-01-12    1\n",
       "2015-01-13    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.groupby([\"date\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c17f425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /home/cdot/.local/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/cdot/.local/lib/python3.10/site-packages (from scipy) (1.23.5)\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3107b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99b276af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankdata(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "540ab0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  rank\n",
       "0 2015-01-01     1\n",
       "1 2015-01-02     2\n",
       "2 2015-01-03     3\n",
       "3 2015-01-06     4\n",
       "4 2015-01-07     5\n",
       "5 2015-01-11     6\n",
       "6 2015-01-12     7\n",
       "7 2015-01-13     8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['rank'] = range(1, len(df1.sort_values(by = \"date\"))+1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5bf73d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date\n",
       "0 2015-01-01\n",
       "1 2015-01-02\n",
       "2 2015-01-03\n",
       "3 2015-01-06\n",
       "4 2015-01-07\n",
       "5 2015-01-11\n",
       "6 2015-01-12\n",
       "7 2015-01-13"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given DataFrame\n",
    "di = {\"date\": [\"01-01-2015\",\"02-01-2015\",\"03-01-2015\",\"06-01-2015\",\n",
    "               \"07-01-2015\",\"11-01-2015\",\"12-01-2015\",\"13-01-2015\"]}\n",
    "\n",
    "df = pd.DataFrame(di)\n",
    "\n",
    "# Convert the 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "12f64be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  day\n",
       "0 2015-01-01    1\n",
       "1 2015-01-02    2\n",
       "2 2015-01-03    3\n",
       "3 2015-01-06    6\n",
       "4 2015-01-07    7\n",
       "5 2015-01-11   11\n",
       "6 2015-01-12   12\n",
       "7 2015-01-13   13"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"day\"] = df[\"date\"].dt.day\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ef01a1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  day\n",
       "0 2015-01-01    1\n",
       "1 2015-01-02    2\n",
       "2 2015-01-03    3\n",
       "3 2015-01-06    6\n",
       "4 2015-01-07    7\n",
       "5 2015-01-11   11\n",
       "6 2015-01-12   12\n",
       "7 2015-01-13   13"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eab236cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (df[\"date\"]!=df[\"date\"].shift()).cumsum()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3ecd729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(t)['date'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a35e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10ec0ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date       rank diff_rank\n",
      "0 2015-01-01        NaT       NaT\n",
      "1 2015-01-02 2015-01-01    1 days\n",
      "2 2015-01-03 2015-01-02    1 days\n",
      "3 2015-01-06 2015-01-03    3 days\n",
      "4 2015-01-07 2015-01-06    1 days\n",
      "5 2015-01-11 2015-01-07    4 days\n",
      "6 2015-01-12 2015-01-11    1 days\n",
      "7 2015-01-13 2015-01-12    1 days\n"
     ]
    }
   ],
   "source": [
    "# Identify the gaps and reset the rank to 1 for the new range\n",
    "df['rank'] = (df['date'].shift())\n",
    "\n",
    "# Display the DataFrame with consecutive ranks\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabb7f2",
   "metadata": {},
   "source": [
    "### To fill te missing values with last Non-NULL categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffab819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import * \n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e44f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/19 15:46:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"myapp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354ab6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://nkt-pe:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>myapp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6977fea500>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afba025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('chocolates','5-star')\n",
    ",(None,'dairy milk')\n",
    ",(None,'perk')\n",
    ",(None,'eclair')\n",
    ",('Biscuits','britannia')\n",
    ",(None,'good day')\n",
    ",(None,'boost')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9bbe964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c31c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[category: string, brand_name: string]\n"
     ]
    }
   ],
   "source": [
    "df = df.toDF(\"category\" , \"brand_name\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ac1e966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[category: string, brand_name: string, order_id: bigint]\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"order_id\" , monotonically_increasing_id())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52a0c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.window.WindowSpec object at 0x7fc5485d8250>\n"
     ]
    }
   ],
   "source": [
    "w_forward = Window.partitionBy().orderBy(\"order_id\"). \\\n",
    "rowsBetween(Window.unboundedPreceding,Window.currentRow) \n",
    "\n",
    "print(w_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f3b87de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/19 13:54:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/01/19 13:54:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/01/19 13:54:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  category|brand_name|\n",
      "+----------+----------+\n",
      "|chocolates|    5-star|\n",
      "|chocolates|dairy milk|\n",
      "|chocolates|      perk|\n",
      "|chocolates|    eclair|\n",
      "|  Biscuits| britannia|\n",
      "|  Biscuits|  good day|\n",
      "|  Biscuits|     boost|\n",
      "+----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:=============================>                             (4 + 4) / 8]\r",
      "24/01/19 13:54:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/01/19 13:54:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.withColumn('category',last('category',ignorenulls=True). \\\n",
    "              over(w_forward)).drop(\"order_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e38e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8071cd",
   "metadata": {},
   "source": [
    "### Calculate the % of marks for each student along with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac7b45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stu_df = [(1,'Steve'),(2,'David'),(3,'Aryan'), (4,'Nandu')]\n",
    "marks_df = [(1,'pyspark',90),(1,'sql',100),\n",
    "            (2,'sql',70),(2,'pyspark',60),\n",
    "            (3,'sql',60),(3,'pyspark',55),\n",
    "            (4,'sql',27),(4,'pyspark',30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee24a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 'Steve'), (2, 'David'), (3, 'Aryan'), (4, 'Nandu')],\n",
       " [(1, 'pyspark', 90),\n",
       "  (1, 'sql', 100),\n",
       "  (2, 'sql', 70),\n",
       "  (2, 'pyspark', 60),\n",
       "  (3, 'sql', 60),\n",
       "  (3, 'pyspark', 55),\n",
       "  (4, 'sql', 27),\n",
       "  (4, 'pyspark', 30)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_df, marks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "024afb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|student_id| name|\n",
      "+----------+-----+\n",
      "|         1|Steve|\n",
      "|         2|David|\n",
      "|         3|Aryan|\n",
      "|         4|Nandu|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stud_data = spark.createDataFrame(stu_df).toDF(\"student_id\" , \"name\")\n",
    "stud_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "294ab341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- student_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stud_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62130782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+\n",
      "|student_id|subject_name|marks|\n",
      "+----------+------------+-----+\n",
      "|         1|     pyspark|   90|\n",
      "|         1|         sql|  100|\n",
      "|         2|         sql|   70|\n",
      "|         2|     pyspark|   60|\n",
      "|         3|         sql|   60|\n",
      "|         3|     pyspark|   55|\n",
      "|         4|         sql|   27|\n",
      "|         4|     pyspark|   30|\n",
      "+----------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marks_data = spark.createDataFrame(marks_df).toDF(\"student_id\" , \"subject_name\", \"marks\")\n",
    "marks_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bfb5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- student_id: long (nullable = true)\n",
      " |-- subject_name: string (nullable = true)\n",
      " |-- marks: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marks_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3fe8d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------+-----+\n",
      "|student_id| name|subject_name|marks|\n",
      "+----------+-----+------------+-----+\n",
      "|         1|Steve|        null| null|\n",
      "|         2|David|        null| null|\n",
      "|         3|Aryan|        null| null|\n",
      "|         4|Nandu|        null| null|\n",
      "|         1| null|     pyspark|   90|\n",
      "|         1| null|         sql|  100|\n",
      "|         2| null|         sql|   70|\n",
      "|         2| null|     pyspark|   60|\n",
      "|         3| null|         sql|   60|\n",
      "|         3| null|     pyspark|   55|\n",
      "|         4| null|         sql|   27|\n",
      "|         4| null|     pyspark|   30|\n",
      "+----------+-----+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stud_data.unionByName(marks_data,allowMissingColumns = True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5024c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------+-----+\n",
      "|student_id| name|subject_name|marks|\n",
      "+----------+-----+------------+-----+\n",
      "|         1|Steve|     pyspark|   90|\n",
      "|         1|Steve|         sql|  100|\n",
      "|         2|David|         sql|   70|\n",
      "|         2|David|     pyspark|   60|\n",
      "|         3|Aryan|         sql|   60|\n",
      "|         3|Aryan|     pyspark|   55|\n",
      "|         4|Nandu|         sql|   27|\n",
      "|         4|Nandu|     pyspark|   30|\n",
      "+----------+-----+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = stud_data.join(marks_data, on = \"student_id\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ee7dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|student_id| name|avg(marks)|\n",
      "+----------+-----+----------+\n",
      "|         1|Steve|      95.0|\n",
      "|         2|David|      65.0|\n",
      "|         3|Aryan|      57.5|\n",
      "|         4|Nandu|      28.5|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_data = joined_df.groupBy([\"student_id\",\"name\"]).avg()\n",
    "drop_unknkwn_group_data = group_data.drop(\"avg(student_id)\")\n",
    "drop_unknkwn_group_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f826f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Percentage: double]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_unknkwn_group_data.select(col(\"avg(marks)\").alias(\"Percentage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "082e8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|student_id| name|Percentage|\n",
      "+----------+-----+----------+\n",
      "|         1|Steve|      95.0|\n",
      "|         2|David|      65.0|\n",
      "|         3|Aryan|      57.5|\n",
      "|         4|Nandu|      28.5|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_data = drop_unknkwn_group_data.withColumnRenamed(\"avg(marks)\", \"Percentage\")\n",
    "percent_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "219fdc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| name|\n",
      "+-----+\n",
      "|Steve|\n",
      "|David|\n",
      "|Aryan|\n",
      "|Nandu|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_data.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2860f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|student_id| name|Percentage|\n",
      "+----------+-----+----------+\n",
      "|         1|Steve|      95.0|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_data.where(col(\"Percentage\")>70).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26d72c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+------------+\n",
      "|student_id| name|Percentage|      Result|\n",
      "+----------+-----+----------+------------+\n",
      "|         1|Steve|      95.0| Distinction|\n",
      "|         2|David|      65.0| First Class|\n",
      "|         3|Aryan|      57.5|Second Class|\n",
      "|         4|Nandu|      28.5|        Fail|\n",
      "+----------+-----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_data.withColumn(\"Result\", when((col(\"Percentage\") >= 70), \"Distinction\"). \\\n",
    "                        when((col(\"Percentage\") >= 60) & (col(\"Percentage\") <= 69), \"First Class\"). \\\n",
    "                        when((col(\"Percentage\") >= 50) & (col(\"Percentage\") <= 59), \"Second Class\"). \\\n",
    "                        when((col(\"Percentage\") >= 40) & (col(\"Percentage\") <= 49), \"Third Class\"). \\\n",
    "                        otherwise(\"Fail\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6de47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
